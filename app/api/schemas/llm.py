from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field
from datetime import datetime


class ChatMessage(BaseModel):
    # # Single chat message in a conversation
    role: str = Field(description="Role of the speaker, e.g. 'user' or 'system'")
    content: str = Field(description="Content of the message")


class ChatRequest(BaseModel):
    # # Request payload for the chat endpoint
    messages: List[ChatMessage] = Field(
        description="Ordered list of messages forming the conversation context"
    )
    stream: bool = Field(
        default=False,
        description="Enable server-side streaming of model outputs",
    )
    max_output_tokens: int = Field(
        default=512,
        ge=1,
        le=8192,
        description="Maximum number of tokens generated by the model",
    )
    temperature: float = Field(
        default=0.3,
        ge=0.0,
        le=2.0,
        description="Sampling temperature for generation",
    )
    top_p: float = Field(
        default=0.95,
        ge=0.0,
        le=1.0,
        description="Top-p nucleus sampling",
    )
    metadata: Optional[Dict[str, Any]] = Field(
        default=None,
        description="Optional caller metadata for observability decorators",
    )


class UsageInfo(BaseModel):
    # # Token usage and derived cost information for observability
    input_tokens: int = 0
    output_tokens: int = 0
    total_tokens: int = 0
    # # You can later compute monetary cost based on pricing tables
    estimated_cost_usd: float = 0.0


class ChatResponse(BaseModel):
    # # Non-streaming response structure
    id: str
    model: str
    created_at: datetime
    latency_ms: float
    usage: UsageInfo
    output_text: str
    raw_model_metadata: Dict[str, Any]
